{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bayes' theorem is a way to calculate conditional probabilities. In this case, we want to find the probability that an employee is a smoker given that he/she uses the health insurance plan. Let's call this event A. Let's call the event that an employee uses the health insurance plan event B.\n",
    "\n",
    ">According to Bayes' theorem, the probability of event A given event B is:\n",
    "\n",
    ">P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    ">We know that P(B|A) is 0.4, because 40% of the employees who use the plan are smokers. We also know that P(B) is 0.7, because 70% of the employees use the company's health insurance plan.\n",
    "\n",
    ">We don't know P(A), which is the probability that an employee is a smoker. However, we don't need to know it in order to calculate P(A|B), because it gets canceled out in the equation.\n",
    "\n",
    ">So, we can calculate P(A|B) as follows:\n",
    "\n",
    ">P(A|B) = (0.4 * P(A)) / 0.7\n",
    "\n",
    ">P(A|B) = 0.4 / 0.7\n",
    "\n",
    ">P(A|B) = 4/7\n",
    "\n",
    ">So, the probability that an employee is a smoker given that he/she uses the health insurance plan is 4/7 or approximately 57.14%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bernoulli Naive Bayes and Multinomial Naive Bayes are two types of Naive Bayes classifiers that are commonly used for text classification and sentiment analysis. The main difference between the two is the type of data they are best suited to work with.\n",
    "\n",
    ">Bernoulli Naive Bayes is used when the features are binary (i.e., they take on only two values, usually 0 and 1) and represent whether a particular word is present or not in a document. It is commonly used for tasks such as spam filtering, where the goal is to classify an email as spam or not spam based on the presence or absence of certain keywords.\n",
    "\n",
    ">On the other hand, Multinomial Naive Bayes is used when the features represent the frequency of occurrence of a particular word in a document or a collection of documents. It is commonly used for tasks such as sentiment analysis, where the goal is to classify a document or a sentence as positive or negative based on the frequency of certain words or phrases.\n",
    "\n",
    ">In summary, Bernoulli Naive Bayes is used for binary data while Multinomial Naive Bayes is used for count data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In Bernoulli Naive Bayes, missing values are treated as a separate category and are not ignored. When there are missing values in the data, the model assumes that the absence of a feature is equivalent to the feature being present and having a value of zero. \n",
    "\n",
    ">For example, suppose a dataset contains a feature for whether a person owns a car, and some of the values are missing. The Bernoulli Naive Bayes model would treat the missing values as a separate category, assuming that the person does not own a car.\n",
    "\n",
    ">This approach is useful when there are many missing values in the dataset, as it allows the model to still make use of the available data. However, it can also lead to biased results if the missing values are not missing at random, i.e., if there is some underlying pattern to their missingness."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Yes, Gaussian Naive Bayes can be used for multi-class classification. It can be extended to multiple classes by using the \"one-vs-all\" or \"one-vs-one\" strategy. In the \"one-vs-all\" strategy, a separate binary Gaussian Naive Bayes classifier is trained for each class, with that class considered as the positive class and the remaining classes considered as the negative class. In the \"one-vs-one\" strategy, a separate binary Gaussian Naive Bayes classifier is trained for each pair of classes, with one class considered as the positive class and the other class considered as the negative class. The final prediction is made by selecting the class with the highest probability from all the binary classifiers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. Assignment:\n",
    "\n",
    "## Data preparation:\n",
    ">Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.\n",
    "\n",
    "## Implementation:\n",
    ">Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "## Results:\n",
    ">Report the following performance metrics for each classifier:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "\n",
    "## Discussion:\n",
    ">Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "## Conclusion:\n",
    ">Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy: 0.8839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8854    0.9286    0.9065      2788\n",
      "           1     0.8813    0.8151    0.8469      1812\n",
      "\n",
      "    accuracy                         0.8839      4600\n",
      "   macro avg     0.8833    0.8719    0.8767      4600\n",
      "weighted avg     0.8838    0.8839    0.8830      4600\n",
      "\n",
      "Multinomial Naive Bayes Accuracy: 0.7861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8203    0.8286    0.8244      2788\n",
      "           1     0.7321    0.7208    0.7264      1812\n",
      "\n",
      "    accuracy                         0.7861      4600\n",
      "   macro avg     0.7762    0.7747    0.7754      4600\n",
      "weighted avg     0.7855    0.7861    0.7858      4600\n",
      "\n",
      "Gaussian Naive Bayes Accuracy: 0.8217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9633    0.7339    0.8331      2788\n",
      "           1     0.7003    0.9570    0.8088      1812\n",
      "\n",
      "    accuracy                         0.8217      4600\n",
      "   macro avg     0.8318    0.8454    0.8209      4600\n",
      "weighted avg     0.8597    0.8217    0.8235      4600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "spam_data = pd.read_csv(r'C:\\Users\\milan\\Documents\\Data Science\\skills\\Notes\\Pandas_\\New Assq\\spambase.csv')\n",
    "X = spam_data.iloc[:, :-1] # input features\n",
    "y = spam_data.iloc[:, -1] # target variable\n",
    "\n",
    "# create Bernoulli Naive Bayes classifier and perform 10-fold cross-validation\n",
    "bnb = BernoulliNB()\n",
    "bnb_scores = cross_val_score(bnb, X, y, cv=10)\n",
    "bnb_pred = cross_val_predict(bnb, X, y, cv=10)\n",
    "\n",
    "# create Multinomial Naive Bayes classifier and perform 10-fold cross-validation\n",
    "mnb = MultinomialNB()\n",
    "mnb_scores = cross_val_score(mnb, X, y, cv=10)\n",
    "mnb_pred = cross_val_predict(mnb, X, y, cv=10)\n",
    "\n",
    "# create Gaussian Naive Bayes classifier and perform 10-fold cross-validation\n",
    "gnb = GaussianNB()\n",
    "gnb_scores = cross_val_score(gnb, X, y, cv=10)\n",
    "gnb_pred = cross_val_predict(gnb, X, y, cv=10)\n",
    "\n",
    "# Bernoulli Naive Bayes classifier evaluation metrics\n",
    "bnb_acc = bnb_scores.mean()\n",
    "bnb_report = classification_report(y, bnb_pred, digits=4)\n",
    "\n",
    "# Multinomial Naive Bayes classifier evaluation metrics\n",
    "mnb_acc = mnb_scores.mean()\n",
    "mnb_report = classification_report(y, mnb_pred, digits=4)\n",
    "\n",
    "# Gaussian Naive Bayes classifier evaluation metrics\n",
    "gnb_acc = gnb_scores.mean()\n",
    "gnb_report = classification_report(y, gnb_pred, digits=4)\n",
    "\n",
    "# print the results\n",
    "print(\"Bernoulli Naive Bayes Accuracy: {:.4f}\".format(bnb_acc))\n",
    "print(bnb_report)\n",
    "print(\"Multinomial Naive Bayes Accuracy: {:.4f}\".format(mnb_acc))\n",
    "print(mnb_report)\n",
    "print(\"Gaussian Naive Bayes Accuracy: {:.4f}\".format(gnb_acc))\n",
    "print(gnb_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
